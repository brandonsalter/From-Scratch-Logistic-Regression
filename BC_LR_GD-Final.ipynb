{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66721cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns', 500)\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score as acc \n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f390fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>radius error</th>\n",
       "      <th>texture error</th>\n",
       "      <th>perimeter error</th>\n",
       "      <th>area error</th>\n",
       "      <th>smoothness error</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>concavity error</th>\n",
       "      <th>concave points error</th>\n",
       "      <th>symmetry error</th>\n",
       "      <th>fractal dimension error</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>1.2560</td>\n",
       "      <td>7.673</td>\n",
       "      <td>158.70</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.02891</td>\n",
       "      <td>0.05198</td>\n",
       "      <td>0.02454</td>\n",
       "      <td>0.01114</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>0.7655</td>\n",
       "      <td>2.4630</td>\n",
       "      <td>5.203</td>\n",
       "      <td>99.04</td>\n",
       "      <td>0.005769</td>\n",
       "      <td>0.02423</td>\n",
       "      <td>0.03950</td>\n",
       "      <td>0.01678</td>\n",
       "      <td>0.01898</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>0.4564</td>\n",
       "      <td>1.0750</td>\n",
       "      <td>3.425</td>\n",
       "      <td>48.55</td>\n",
       "      <td>0.005903</td>\n",
       "      <td>0.03731</td>\n",
       "      <td>0.04730</td>\n",
       "      <td>0.01557</td>\n",
       "      <td>0.01318</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>0.7260</td>\n",
       "      <td>1.5950</td>\n",
       "      <td>5.772</td>\n",
       "      <td>86.22</td>\n",
       "      <td>0.006522</td>\n",
       "      <td>0.06158</td>\n",
       "      <td>0.07117</td>\n",
       "      <td>0.01664</td>\n",
       "      <td>0.02324</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>1.4280</td>\n",
       "      <td>2.548</td>\n",
       "      <td>19.15</td>\n",
       "      <td>0.007189</td>\n",
       "      <td>0.00466</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.02676</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  radius error  texture error  perimeter error  \\\n",
       "0                   0.07871        1.0950         0.9053            8.589   \n",
       "1                   0.05667        0.5435         0.7339            3.398   \n",
       "2                   0.05999        0.7456         0.7869            4.585   \n",
       "3                   0.09744        0.4956         1.1560            3.445   \n",
       "4                   0.05883        0.7572         0.7813            5.438   \n",
       "..                      ...           ...            ...              ...   \n",
       "564                 0.05623        1.1760         1.2560            7.673   \n",
       "565                 0.05533        0.7655         2.4630            5.203   \n",
       "566                 0.05648        0.4564         1.0750            3.425   \n",
       "567                 0.07016        0.7260         1.5950            5.772   \n",
       "568                 0.05884        0.3857         1.4280            2.548   \n",
       "\n",
       "     area error  smoothness error  compactness error  concavity error  \\\n",
       "0        153.40          0.006399            0.04904          0.05373   \n",
       "1         74.08          0.005225            0.01308          0.01860   \n",
       "2         94.03          0.006150            0.04006          0.03832   \n",
       "3         27.23          0.009110            0.07458          0.05661   \n",
       "4         94.44          0.011490            0.02461          0.05688   \n",
       "..          ...               ...                ...              ...   \n",
       "564      158.70          0.010300            0.02891          0.05198   \n",
       "565       99.04          0.005769            0.02423          0.03950   \n",
       "566       48.55          0.005903            0.03731          0.04730   \n",
       "567       86.22          0.006522            0.06158          0.07117   \n",
       "568       19.15          0.007189            0.00466          0.00000   \n",
       "\n",
       "     concave points error  symmetry error  fractal dimension error  \\\n",
       "0                 0.01587         0.03003                 0.006193   \n",
       "1                 0.01340         0.01389                 0.003532   \n",
       "2                 0.02058         0.02250                 0.004571   \n",
       "3                 0.01867         0.05963                 0.009208   \n",
       "4                 0.01885         0.01756                 0.005115   \n",
       "..                    ...             ...                      ...   \n",
       "564               0.02454         0.01114                 0.004239   \n",
       "565               0.01678         0.01898                 0.002498   \n",
       "566               0.01557         0.01318                 0.003892   \n",
       "567               0.01664         0.02324                 0.006185   \n",
       "568               0.00000         0.02676                 0.002783   \n",
       "\n",
       "     worst radius  worst texture  worst perimeter  worst area  \\\n",
       "0          25.380          17.33           184.60      2019.0   \n",
       "1          24.990          23.41           158.80      1956.0   \n",
       "2          23.570          25.53           152.50      1709.0   \n",
       "3          14.910          26.50            98.87       567.7   \n",
       "4          22.540          16.67           152.20      1575.0   \n",
       "..            ...            ...              ...         ...   \n",
       "564        25.450          26.40           166.10      2027.0   \n",
       "565        23.690          38.25           155.00      1731.0   \n",
       "566        18.980          34.12           126.70      1124.0   \n",
       "567        25.740          39.42           184.60      1821.0   \n",
       "568         9.456          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,y = load_breast_cancer(return_X_y=True,as_frame=True)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93ced3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "564    0\n",
       "565    0\n",
       "566    0\n",
       "567    0\n",
       "568    1\n",
       "Name: target, Length: 569, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f13c2258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[212 357]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y))\n",
    "print(np.bincount(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dad165",
   "metadata": {},
   "source": [
    "# Gradient Descent Based Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c109b18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR_GD:\n",
    "    \n",
    "    def __init__(self, eta = 0.01, n_iter = 50, random_state = 1):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = rgen.normal(loc = 0.0, scale = 0.01, size = X.shape[1])\n",
    "        self.b_ = np.float_(0.)\n",
    "        self.losses_ = []\n",
    "        \n",
    "        for i in range(self.n_iter):\n",
    "            net_input = self.net_input(X)\n",
    "            output = self.activation(net_input)\n",
    "            errors = (y - output)\n",
    "            self.w_ += self.eta * X.T.dot(errors) / X.shape[0] \n",
    "            self.b_ += self.eta * errors.mean()\n",
    "            loss = (-y.dot(np.log(output)) - ((1-y).dot(np.log(1 - output))) / X.shape[0])\n",
    "            self.losses_.append(loss)\n",
    "        return self\n",
    "    \n",
    "    def net_input(self, X):\n",
    "        return np.dot(X, self.w_) + self.b_\n",
    "    \n",
    "    def activation(self, z):\n",
    "        return 1. / (1. + np.exp(-np.clip(z, -250, 250)))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.where(self.activation(self.net_input(X)) >= 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0710f92",
   "metadata": {},
   "source": [
    "# 5-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "421312c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cv, X_test_cv, y_train_cv, y_test_cv = train_test_split(X, y, test_size = 0.2, random_state = 42, \n",
    "                                                                shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b18780f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit(X_train_cv)\n",
    "X_train_std_cv = sc.transform(X_train_cv)\n",
    "X_test_std_cv = sc.transform(X_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af219db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_fold_cv(eta, n_iter):\n",
    "    \n",
    "    df = pd.DataFrame(data=X_train_std_cv)\n",
    "    df['Label'] = y_train_cv\n",
    "    \n",
    "    n = len(df)//5\n",
    "    \n",
    "    lr_cv0 = LR_GD(eta, n_iter)\n",
    "    lr_cv1 = LR_GD(eta, n_iter)\n",
    "    lr_cv2 = LR_GD(eta, n_iter)\n",
    "    lr_cv3 = LR_GD(eta, n_iter)\n",
    "    lr_cv4 = LR_GD(eta, n_iter)\n",
    "     \n",
    "    acc_lst = []\n",
    "    \n",
    "    for i in range(5):\n",
    "\n",
    "        df = df.reindex(np.random.permutation(df.index))  \n",
    "        df = df.reset_index(drop=True) \n",
    "    \n",
    "        fold1 = df.loc[0:n-1]\n",
    "        fold2 = df.loc[n:2*n-1]\n",
    "        fold3 = df.loc[2*n:3*n-1]\n",
    "        fold4 = df.loc[3*n:4*n-1]\n",
    "        fold5 = df.loc[4*n:]\n",
    "\n",
    "        if i == 0:\n",
    "            train_val = pd.concat([fold1, fold2, fold3, fold4])\n",
    "            test_val = fold5\n",
    "        \n",
    "            training_features = train_val.iloc[:,0:30].values\n",
    "            training_labels = train_val.iloc[:,-1].values\n",
    "        \n",
    "            test_features = test_val.iloc[:,0:30].values\n",
    "            test_labels = test_val.iloc[:,-1].values\n",
    "        \n",
    "            lr_cv0.fit(training_features, training_labels)\n",
    "            y_pred_cv = lr_cv0.predict(test_features)\n",
    "        \n",
    "            accuracy = acc(y_pred_cv, test_labels)\n",
    "                           \n",
    "            acc_lst.append(accuracy)\n",
    "\n",
    "        elif i == 1:\n",
    "            train_val = pd.concat([fold1, fold2, fold3, fold5])\n",
    "            test_val = fold4\n",
    "        \n",
    "            training_features = train_val.iloc[:,0:30].values\n",
    "            training_labels = train_val.iloc[:,-1].values\n",
    "        \n",
    "            test_features = test_val.iloc[:,0:30].values\n",
    "            test_labels = test_val.iloc[:,-1].values\n",
    "        \n",
    "            lr_cv1.fit(training_features, training_labels)\n",
    "            y_pred_cv = lr_cv1.predict(test_features)\n",
    "        \n",
    "            accuracy = acc(y_pred_cv, test_labels)\n",
    "                           \n",
    "            acc_lst.append(accuracy)\n",
    "\n",
    "        elif i == 2:\n",
    "            train_val = pd.concat([fold1, fold2, fold4, fold5])\n",
    "            test_val = fold3\n",
    "\n",
    "            training_features = train_val.iloc[:,0:30].values\n",
    "            training_labels = train_val.iloc[:,-1].values\n",
    "        \n",
    "            test_features = test_val.iloc[:,0:30].values\n",
    "            test_labels = test_val.iloc[:,-1].values\n",
    "        \n",
    "            lr_cv2.fit(training_features, training_labels)\n",
    "            y_pred_cv = lr_cv2.predict(test_features)\n",
    "        \n",
    "            accuracy = acc(y_pred_cv, test_labels)\n",
    "            \n",
    "            acc_lst.append(accuracy)\n",
    "\n",
    "        elif i == 3:\n",
    "            train_val = pd.concat([fold1, fold3, fold4, fold5])\n",
    "            test_val = fold2\n",
    "        \n",
    "            training_features = train_val.iloc[:,0:30].values\n",
    "            training_labels = train_val.iloc[:,-1].values\n",
    "        \n",
    "            test_features = test_val.iloc[:,0:30].values\n",
    "            test_labels = test_val.iloc[:,-1].values\n",
    "        \n",
    "            lr_cv3.fit(training_features, training_labels)\n",
    "            y_pred_cv = lr_cv3.predict(test_features)\n",
    "            \n",
    "            accuracy = acc(y_pred_cv, test_labels)\n",
    "            \n",
    "            acc_lst.append(accuracy)\n",
    "         \n",
    "        elif i == 4:\n",
    "            train_val = pd.concat([fold2, fold3, fold4, fold5])\n",
    "            test_val = fold1\n",
    "                    \n",
    "            training_features = train_val.iloc[:,0:30].values\n",
    "            training_labels = train_val.iloc[:,-1].values\n",
    "        \n",
    "            test_features = test_val.iloc[:,0:30].values\n",
    "            test_labels = test_val.iloc[:,-1].values\n",
    "        \n",
    "            lr_cv4.fit(training_features, training_labels)\n",
    "            y_pred_cv = lr_cv4.predict(test_features)\n",
    "        \n",
    "            accuracy = acc(y_pred_cv, test_labels)\n",
    "\n",
    "            acc_lst.append(accuracy)\n",
    "        \n",
    "    return [acc_lst,('Avg Accuracy:',(np.round(sum(acc_lst) / len(acc_lst),5)))];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67865fd2",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a5c2353",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = []\n",
    "etas = [0.001, 0.005, 0.01, 0.015, 0.02, 0.025]\n",
    "iters = [500, 1000, 1500, 2000, 2500, 3000, 3500, 4000]\n",
    "for i in itertools.product(etas, iters):\n",
    "    params.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d29833ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(params):\n",
    "    best = 0\n",
    "    index = 0\n",
    "    for i in range(len(params)):\n",
    "        x = five_fold_cv(eta = params[i][0], n_iter = params[i][1])\n",
    "        if x[1][1] > best:\n",
    "            best = x[1][1] \n",
    "            index = i\n",
    "            print(f'Accuracy: {best}, Index: {i}')\n",
    "    return(f'Best Parameters: {params[index]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5ff03f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.93187, Index: 0\n",
      "Accuracy: 0.96044, Index: 1\n",
      "Accuracy: 0.96484, Index: 5\n",
      "Accuracy: 0.97582, Index: 8\n",
      "Accuracy: 0.98022, Index: 16\n",
      "Accuracy: 0.98242, Index: 25\n",
      "Accuracy: 0.98462, Index: 28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Best Parameters: (0.015, 2500)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9cbbd5",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c02769aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01e75c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1fb5bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LR_GD at 0x7fde04840790>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LR_GD(eta = 0.015, n_iter = 2500)\n",
    "lr.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3dde7260",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = lr.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "508c4458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9824561403508771"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(y_pred_lr, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef18cc2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, len(lr.losses_) + 1), \n",
    "        lr.losses_, marker = 'o')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17d7a631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 20, 112])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc = np.where(y_pred_lr != y_test)[0]\n",
    "mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7009fd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_table = pd.DataFrame(X_test.to_numpy()[y] for y in mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96658d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>radius error</th>\n",
       "      <th>texture error</th>\n",
       "      <th>perimeter error</th>\n",
       "      <th>area error</th>\n",
       "      <th>smoothness error</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>concavity error</th>\n",
       "      <th>concave points error</th>\n",
       "      <th>symmetry error</th>\n",
       "      <th>fractal dimension error</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>Actual Label</th>\n",
       "      <th>Predicted Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.80</td>\n",
       "      <td>15.79</td>\n",
       "      <td>90.43</td>\n",
       "      <td>584.1</td>\n",
       "      <td>0.10070</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>0.07789</td>\n",
       "      <td>0.05069</td>\n",
       "      <td>0.1662</td>\n",
       "      <td>0.06566</td>\n",
       "      <td>0.2787</td>\n",
       "      <td>0.6205</td>\n",
       "      <td>1.957</td>\n",
       "      <td>23.35</td>\n",
       "      <td>0.004717</td>\n",
       "      <td>0.02065</td>\n",
       "      <td>0.01759</td>\n",
       "      <td>0.009206</td>\n",
       "      <td>0.01220</td>\n",
       "      <td>0.003130</td>\n",
       "      <td>16.57</td>\n",
       "      <td>20.86</td>\n",
       "      <td>110.3</td>\n",
       "      <td>812.4</td>\n",
       "      <td>0.1411</td>\n",
       "      <td>0.3542</td>\n",
       "      <td>0.2779</td>\n",
       "      <td>0.13830</td>\n",
       "      <td>0.2589</td>\n",
       "      <td>0.10300</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.22</td>\n",
       "      <td>27.85</td>\n",
       "      <td>92.55</td>\n",
       "      <td>623.9</td>\n",
       "      <td>0.08223</td>\n",
       "      <td>0.1039</td>\n",
       "      <td>0.11030</td>\n",
       "      <td>0.04408</td>\n",
       "      <td>0.1342</td>\n",
       "      <td>0.06129</td>\n",
       "      <td>0.3354</td>\n",
       "      <td>2.3240</td>\n",
       "      <td>2.105</td>\n",
       "      <td>29.96</td>\n",
       "      <td>0.006307</td>\n",
       "      <td>0.02845</td>\n",
       "      <td>0.03850</td>\n",
       "      <td>0.010110</td>\n",
       "      <td>0.01185</td>\n",
       "      <td>0.003589</td>\n",
       "      <td>15.75</td>\n",
       "      <td>40.54</td>\n",
       "      <td>102.5</td>\n",
       "      <td>764.0</td>\n",
       "      <td>0.1081</td>\n",
       "      <td>0.2426</td>\n",
       "      <td>0.3064</td>\n",
       "      <td>0.08219</td>\n",
       "      <td>0.1890</td>\n",
       "      <td>0.07796</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        13.80         15.79           90.43      584.1          0.10070   \n",
       "1        14.22         27.85           92.55      623.9          0.08223   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0            0.1280         0.07789              0.05069         0.1662   \n",
       "1            0.1039         0.11030              0.04408         0.1342   \n",
       "\n",
       "   mean fractal dimension  radius error  texture error  perimeter error  \\\n",
       "0                 0.06566        0.2787         0.6205            1.957   \n",
       "1                 0.06129        0.3354         2.3240            2.105   \n",
       "\n",
       "   area error  smoothness error  compactness error  concavity error  \\\n",
       "0       23.35          0.004717            0.02065          0.01759   \n",
       "1       29.96          0.006307            0.02845          0.03850   \n",
       "\n",
       "   concave points error  symmetry error  fractal dimension error  \\\n",
       "0              0.009206         0.01220                 0.003130   \n",
       "1              0.010110         0.01185                 0.003589   \n",
       "\n",
       "   worst radius  worst texture  worst perimeter  worst area  worst smoothness  \\\n",
       "0         16.57          20.86            110.3       812.4            0.1411   \n",
       "1         15.75          40.54            102.5       764.0            0.1081   \n",
       "\n",
       "   worst compactness  worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.3542           0.2779               0.13830          0.2589   \n",
       "1             0.2426           0.3064               0.08219          0.1890   \n",
       "\n",
       "   worst fractal dimension  Actual Label  Predicted Label  \n",
       "0                  0.10300             0                1  \n",
       "1                  0.07796             1                0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_table = mc_table.rename(columns={0:'mean radius',1:'mean texture',2:'mean perimeter',3:'mean area',4:'mean smoothness',\n",
    "                                    5:'mean compactness', 6:'mean concavity',7:'mean concave points',8:'mean symmetry',\n",
    "                                    9:'mean fractal dimension',10:'radius error', 11:'texture error', 12:'perimeter error',\n",
    "                                    13:'area error',14:'smoothness error',15:'compactness error',16:'concavity error',17:'concave points error',\n",
    "                                    18:'symmetry error',19:'fractal dimension error',20:'worst radius',21:'worst texture',\n",
    "                                    22:'worst perimeter',23:'worst area',24:'worst smoothness',25:'worst compactness',\n",
    "                                    26:'worst concavity',27:'worst concave points',28:'worst symmetry',29:'worst fractal dimension',})\n",
    "\n",
    "mc_table['Actual Label'] = [y_test.iloc[y] for y in mc]\n",
    "mc_table['Predicted Label'] = [y_pred_lr[y] for y in mc]\n",
    "mc_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eaf75f20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[42,  1],\n",
       "       [ 1, 70]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50fd89b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
